{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "# from torchsummary import summary\n",
    "from torchinfo import summary\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# check OS is Window or Mac\n",
    "import platform\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "elif platform.system() == 'Darwin':\n",
    "    try:\n",
    "        device = torch.device(\"mps\")\n",
    "    except:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "float_formatter = \"{:.2f}\".format\n",
    "np.set_printoptions(formatter={'float_kind': float_formatter})\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFCNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomFCNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(19200, 128)  # Update fc1 input size to match the expected size\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 60)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(60, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class LeNet5V1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            # 1\n",
    "            nn.Conv2d(in_channels=3,    # cantidad de canales RGB == 3\n",
    "                      out_channels=6, \n",
    "                      kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # 2\n",
    "            nn.Conv2d(in_channels=6, \n",
    "                      out_channels=16,\n",
    "                      kernel_size=5, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16*22*22, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=10),\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    modelFCN = CustomFCNetwork()\n",
    "    model_name = \"FCN_final\"\n",
    "    modelFCN.load_state_dict(torch.load(f\"models/best_model_{model_name}.pth\", map_location=torch.device('cpu')))\n",
    "    modelFCN.eval()  # Set model to evaluation mode after loading\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    modelCNN = LeNet5V1()\n",
    "    model_name = \"LeNet5_final\"\n",
    "    modelCNN.load_state_dict(torch.load(f\"models/best_model_{model_name}.pth\", map_location=torch.device('cpu')))\n",
    "    modelCNN.eval()  # Set model to evaluation mode after loading\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './img/'\n",
    "batch_size = 8 \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((80, 80)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root='./data_split/train', transform=transform)\n",
    "val_dataset = ImageFolder(root='./data_split/test', transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar adversial images\n",
    "def fgsm_attack(data, target, model, epsilon=0.03):\n",
    "    data.requires_grad = True\n",
    "    output = model(data)\n",
    "    loss = F.cross_entropy(output, target)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    perturbed_data = data + epsilon * data.grad.sign()\n",
    "    perturbed_data = torch.clamp(perturbed_data, 0, 1)  # Ensure pixel values are within valid range\n",
    "    return perturbed_data\n",
    "\n",
    "def adversarial_training(model, model_name):\n",
    "    # training loop\n",
    "    num_epochs = 10\n",
    "    epsilon = 0.03  #magnitud de la pertubaci√≥n\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # genera adversarial images\n",
    "            adv_images = fgsm_attack(images, labels, model, epsilon)\n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(torch.cat((images, adv_images), dim=0))\n",
    "            combined_labels = torch.cat((labels, labels), dim=0)\n",
    "            loss = criterion(outputs, combined_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = outputs.max(1)\n",
    "            total += combined_labels.size(0)\n",
    "            correct += predicted.eq(combined_labels).sum().item()\n",
    "        \n",
    "        # Print statistics\n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        if (epoch == 8):  # Adjust the frequency of saving checkpoints as needed\n",
    "            checkpoint_path = \"./models/\" + f'adversarial_{model_name}.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                # Add other relevant training parameters or state\n",
    "            }, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_training(modelFCN, \"FCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_training(modelCNN,\"LeNet5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
