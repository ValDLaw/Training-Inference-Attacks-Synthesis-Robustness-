{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f633f0509d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "pretrained_model = \"models/best_model_FCN_final.pth\"\n",
    "use_cuda=False\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/enzoc/Escritorio/lab4ML/Training-Inference-Attacks-Synthesis-Robustness-\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/best_model_CNN_final.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/enzoc/Escritorio/lab4ML/Training-Inference-Attacks-Synthesis-Robustness-/bola.ipynb Celda 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/enzoc/Escritorio/lab4ML/Training-Inference-Attacks-Synthesis-Robustness-/bola.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m epsilons \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.15\u001b[39m, \u001b[39m0.2\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/enzoc/Escritorio/lab4ML/Training-Inference-Attacks-Synthesis-Robustness-/bola.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Load your pretrained models\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/enzoc/Escritorio/lab4ML/Training-Inference-Attacks-Synthesis-Robustness-/bola.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pretrained_cnn_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mmodels/best_model_CNN_final.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/enzoc/Escritorio/lab4ML/Training-Inference-Attacks-Synthesis-Robustness-/bola.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pretrained_fcn_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mmodels/best_model_FCN_final.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/enzoc/Escritorio/lab4ML/Training-Inference-Attacks-Synthesis-Robustness-/bola.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Assuming you have a DataLoader for your dataset\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/enzoc/Escritorio/lab4ML/Training-Inference-Attacks-Synthesis-Robustness-/bola.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Modify the dataset loading and model usage based on your implementation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/enzoc/Escritorio/lab4ML/Training-Inference-Attacks-Synthesis-Robustness-/bola.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# For simplicity, I'll assume you're using ImageFolder\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    436\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/best_model_CNN_final.pth'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the epsilon values\n",
    "epsilons = [0, 0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "# Load your pretrained models\n",
    "pretrained_cnn_model_path = \"models/best_model_CNN_final.pth\"\n",
    "pretrained_fcn_model_path = \"models/best_model_FCN_final.pth\"\n",
    "\n",
    "\n",
    "# Load your pretrained models\n",
    "pretrained_cnn_model = torch.load(pretrained_cnn_model_path)\n",
    "pretrained_fcn_model = torch.load(pretrained_fcn_model_path)\n",
    "\n",
    "# Assuming you have a DataLoader for your dataset\n",
    "# Modify the dataset loading and model usage based on your implementation\n",
    "# For simplicity, I'll assume you're using ImageFolder\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Replace 'your_dataset_path' with the path to your dataset\n",
    "dataset = ImageFolder(root='./data_split/test/', transform=data_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Function to perform FGSM attack\n",
    "def fgsm_attack(model, image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    \n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    \n",
    "    # Clip the perturbed image to ensure it stays within the valid pixel range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    \n",
    "    return perturbed_image\n",
    "\n",
    "# Function to evaluate the model on the test dataset\n",
    "def test_model(model, dataloader, epsilon):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and compute gradient\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Collect data gradient\n",
    "        data_grad = inputs.grad.data\n",
    "        \n",
    "        # Perform FGSM attack\n",
    "        perturbed_inputs = fgsm_attack(model, inputs, epsilon, data_grad)\n",
    "        \n",
    "        # Forward pass on the perturbed image\n",
    "        perturbed_outputs = model(perturbed_inputs)\n",
    "        \n",
    "        # Check the accuracy on the perturbed image\n",
    "        _, perturbed_predicted = torch.max(perturbed_outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (perturbed_predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Perform FGSM attack for both CNN and FCN\n",
    "accuracies_cnn = []\n",
    "accuracies_fcn = []\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    acc_cnn = test_model(pretrained_cnn_model, dataloader, epsilon)\n",
    "    acc_fcn = test_model(pretrained_fcn_model, dataloader, epsilon)\n",
    "    \n",
    "    accuracies_cnn.append(acc_cnn)\n",
    "    accuracies_fcn.append(acc_fcn)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epsilons, accuracies_cnn, marker='o')\n",
    "plt.title('CNN Adversarial Attack')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epsilons, accuracies_fcn, marker='o')\n",
    "plt.title('FCN Adversarial Attack')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
